{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rJf3qBvvuYRA"
   },
   "source": [
    "# Week 10 - PCA and Dimension Reduction Homework\n",
    "Execute the below code and answer the following questions. __Do NOT commit the csv file!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-C2i3-1auYRC"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "def generate_data():\n",
    "    x, y = make_classification(n_samples=1500, \n",
    "                            n_features = 20,\n",
    "                            n_informative = 8,\n",
    "                            n_redundant = 5,\n",
    "                            n_repeated = 1, \n",
    "                            n_classes = 3,\n",
    "                            weights = (0.5, 0.25, 0.25),\n",
    "                            random_state = 120\n",
    "                            )\n",
    "    colNames = ['var'+str(x) for x in range(20)]\n",
    "    colNames.append('target')\n",
    "\n",
    "    df = pd.DataFrame(np.concatenate((x,y.reshape(-1,1)), axis=1), columns=colNames)\n",
    "    df.to_csv('pca-dataset.csv', index=False)\n",
    "    \n",
    "generate_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "4m2anV8vuYRD",
    "outputId": "0103f11f-4ec1-4d70-819f-818a0b00a16e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var0</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>var3</th>\n",
       "      <th>var4</th>\n",
       "      <th>var5</th>\n",
       "      <th>var6</th>\n",
       "      <th>var7</th>\n",
       "      <th>var8</th>\n",
       "      <th>var9</th>\n",
       "      <th>...</th>\n",
       "      <th>var11</th>\n",
       "      <th>var12</th>\n",
       "      <th>var13</th>\n",
       "      <th>var14</th>\n",
       "      <th>var15</th>\n",
       "      <th>var16</th>\n",
       "      <th>var17</th>\n",
       "      <th>var18</th>\n",
       "      <th>var19</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.882513</td>\n",
       "      <td>-3.272465</td>\n",
       "      <td>-2.520732</td>\n",
       "      <td>-1.987174</td>\n",
       "      <td>-2.073689</td>\n",
       "      <td>-3.272465</td>\n",
       "      <td>-1.237969</td>\n",
       "      <td>1.690547</td>\n",
       "      <td>-0.211314</td>\n",
       "      <td>-5.753190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.574979</td>\n",
       "      <td>-1.916275</td>\n",
       "      <td>-5.994075</td>\n",
       "      <td>-3.349615</td>\n",
       "      <td>-0.846193</td>\n",
       "      <td>2.491347</td>\n",
       "      <td>1.360958</td>\n",
       "      <td>-2.892522</td>\n",
       "      <td>-1.377561</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.775242</td>\n",
       "      <td>-1.015994</td>\n",
       "      <td>0.005137</td>\n",
       "      <td>0.057274</td>\n",
       "      <td>0.590205</td>\n",
       "      <td>-1.015994</td>\n",
       "      <td>1.350954</td>\n",
       "      <td>-1.493037</td>\n",
       "      <td>-0.862391</td>\n",
       "      <td>-1.986047</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523760</td>\n",
       "      <td>0.399579</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.718606</td>\n",
       "      <td>-1.112030</td>\n",
       "      <td>0.083929</td>\n",
       "      <td>0.606544</td>\n",
       "      <td>-1.376793</td>\n",
       "      <td>1.302641</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.876376</td>\n",
       "      <td>0.220453</td>\n",
       "      <td>3.114224</td>\n",
       "      <td>-1.640025</td>\n",
       "      <td>1.180348</td>\n",
       "      <td>0.220453</td>\n",
       "      <td>0.465102</td>\n",
       "      <td>0.222511</td>\n",
       "      <td>0.880455</td>\n",
       "      <td>2.922315</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.370516</td>\n",
       "      <td>3.585262</td>\n",
       "      <td>-2.168162</td>\n",
       "      <td>2.693429</td>\n",
       "      <td>-0.966636</td>\n",
       "      <td>1.586302</td>\n",
       "      <td>-2.821546</td>\n",
       "      <td>0.482164</td>\n",
       "      <td>0.187404</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.550342</td>\n",
       "      <td>-1.968144</td>\n",
       "      <td>0.077681</td>\n",
       "      <td>-1.887719</td>\n",
       "      <td>1.864445</td>\n",
       "      <td>-1.968144</td>\n",
       "      <td>-0.527958</td>\n",
       "      <td>-0.201467</td>\n",
       "      <td>-0.532649</td>\n",
       "      <td>2.287445</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041341</td>\n",
       "      <td>2.383582</td>\n",
       "      <td>-0.417253</td>\n",
       "      <td>1.305379</td>\n",
       "      <td>-0.435123</td>\n",
       "      <td>-0.468557</td>\n",
       "      <td>0.923290</td>\n",
       "      <td>3.880050</td>\n",
       "      <td>2.676798</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.454974</td>\n",
       "      <td>1.293300</td>\n",
       "      <td>0.112201</td>\n",
       "      <td>-0.589989</td>\n",
       "      <td>-1.674321</td>\n",
       "      <td>1.293300</td>\n",
       "      <td>0.487302</td>\n",
       "      <td>1.776318</td>\n",
       "      <td>0.702520</td>\n",
       "      <td>-1.024127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.452869</td>\n",
       "      <td>-0.667306</td>\n",
       "      <td>0.345364</td>\n",
       "      <td>-3.920591</td>\n",
       "      <td>-0.438296</td>\n",
       "      <td>-1.690141</td>\n",
       "      <td>0.176906</td>\n",
       "      <td>1.920142</td>\n",
       "      <td>1.474634</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       var0      var1      var2      var3      var4      var5      var6  \\\n",
       "0 -2.882513 -3.272465 -2.520732 -1.987174 -2.073689 -3.272465 -1.237969   \n",
       "1  0.775242 -1.015994  0.005137  0.057274  0.590205 -1.015994  1.350954   \n",
       "2 -0.876376  0.220453  3.114224 -1.640025  1.180348  0.220453  0.465102   \n",
       "3 -2.550342 -1.968144  0.077681 -1.887719  1.864445 -1.968144 -0.527958   \n",
       "4 -0.454974  1.293300  0.112201 -0.589989 -1.674321  1.293300  0.487302   \n",
       "\n",
       "       var7      var8      var9  ...     var11     var12     var13     var14  \\\n",
       "0  1.690547 -0.211314 -5.753190  ... -0.574979 -1.916275 -5.994075 -3.349615   \n",
       "1 -1.493037 -0.862391 -1.986047  ...  0.523760  0.399579  0.088600  0.718606   \n",
       "2  0.222511  0.880455  2.922315  ... -0.370516  3.585262 -2.168162  2.693429   \n",
       "3 -0.201467 -0.532649  2.287445  ... -0.041341  2.383582 -0.417253  1.305379   \n",
       "4  1.776318  0.702520 -1.024127  ... -0.452869 -0.667306  0.345364 -3.920591   \n",
       "\n",
       "      var15     var16     var17     var18     var19  target  \n",
       "0 -0.846193  2.491347  1.360958 -2.892522 -1.377561     0.0  \n",
       "1 -1.112030  0.083929  0.606544 -1.376793  1.302641     2.0  \n",
       "2 -0.966636  1.586302 -2.821546  0.482164  0.187404     0.0  \n",
       "3 -0.435123 -0.468557  0.923290  3.880050  2.676798     1.0  \n",
       "4 -0.438296 -1.690141  0.176906  1.920142  1.474634     0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('pca-dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "vhw3jMhbuYRE",
    "outputId": "7f73da21-a10f-47f6-c0b9-d487a594afb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 21 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   var0    1500 non-null   float64\n",
      " 1   var1    1500 non-null   float64\n",
      " 2   var2    1500 non-null   float64\n",
      " 3   var3    1500 non-null   float64\n",
      " 4   var4    1500 non-null   float64\n",
      " 5   var5    1500 non-null   float64\n",
      " 6   var6    1500 non-null   float64\n",
      " 7   var7    1500 non-null   float64\n",
      " 8   var8    1500 non-null   float64\n",
      " 9   var9    1500 non-null   float64\n",
      " 10  var10   1500 non-null   float64\n",
      " 11  var11   1500 non-null   float64\n",
      " 12  var12   1500 non-null   float64\n",
      " 13  var13   1500 non-null   float64\n",
      " 14  var14   1500 non-null   float64\n",
      " 15  var15   1500 non-null   float64\n",
      " 16  var16   1500 non-null   float64\n",
      " 17  var17   1500 non-null   float64\n",
      " 18  var18   1500 non-null   float64\n",
      " 19  var19   1500 non-null   float64\n",
      " 20  target  1500 non-null   float64\n",
      "dtypes: float64(21)\n",
      "memory usage: 246.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hhWfFtFGuYRF",
    "outputId": "135b24ea-fa49-4f29-9716-cffb984abdd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1,200\n",
      "Test samples: 300\n",
      "\n",
      "Features:\n",
      "var0\tvar1\tvar2\tvar3\tvar4\tvar5\tvar6\tvar7\tvar8\tvar9\tvar10\tvar11\tvar12\tvar13\tvar14\tvar15\tvar16\tvar17\tvar18\tvar19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df[[x for x in df.columns if x.startswith('var')]]\n",
    "y = df['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "print(f'Training samples: {X_train.shape[0]:,}')\n",
    "print(f'Test samples: {X_test.shape[0]:,}')\n",
    "\n",
    "print('\\nFeatures:')\n",
    "print(*X_train, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGjpHCUguYRF"
   },
   "source": [
    "### Data Description\n",
    "- `var1 - var19`: a feature for the data.  \n",
    "- `target`: variable we wish to be able to predict, which is 1 of 3 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eu43exbquYRG"
   },
   "source": [
    "# Question 1\n",
    "- Use principle components analysis to determine the number of components to reduce the data to by evaluating the explained variance ratio (use `X_train`).  \n",
    "- Remember to scale the data first.  \n",
    "- What number of components would you recommend based on your analysis?  \n",
    "- Explain your results using markdown cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kEXTGlkJuYRG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components to explain 95% of variance: 13\n"
     ]
    }
   ],
   "source": [
    "# insert code here\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Apply PCA to determine the number of components to use\n",
    "pca = PCA()\n",
    "pca.fit(X_scaled)\n",
    "cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)\n",
    "num_components = np.argmax(cumulative_variance_ratio >= 0.95) + 1\n",
    "print(f'Number of components to explain 95% of variance: {num_components}')\n",
    "\n",
    "# Transform the data to the reduced dimensionality\n",
    "pca = PCA(n_components=num_components)\n",
    "X_pca = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h__Ig0EAuYRG"
   },
   "source": [
    "> Describe your results here\n",
    "\n",
    "Above analysis shows the cumulative percentage of the total variation in the data that is explained by each component. This number can be used to estimate the number of components needed to explain a particular amount of variance.\n",
    "\n",
    "We can see that in this case, 13 components are required to explain 95% of the data variation. After 13 components, the marginal gain in explained variance starts to decline, indicating that more components are unlikely to add much new information. The most important patterns should therefore be preserved while the feature space is reduced by splitting the data into 13 components."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K4lOui0VuYRH"
   },
   "source": [
    "<Insert comments>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HjPfGpvAuYRH"
   },
   "source": [
    "# Question 2\n",
    "- Evaluate the target variable in the `df` object.  \n",
    "- Which metric would you use in evaluating a predictive model. Explain your choice in the markdown cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GzLRT0mmuYRJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Mean: 0.7573333333333333\n",
      "Target Median: 1.0\n",
      "Target Standard Deviation: 0.831208052639888\n",
      "Target Minimum: 0.0\n",
      "Target Maximum: 2.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Insert code here\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculation of basic statistics\n",
    "target_mean = df['target'].mean()\n",
    "target_median = df['target'].median()\n",
    "target_std = df['target'].std()\n",
    "target_min = df['target'].min()\n",
    "target_max = df['target'].max()\n",
    "\n",
    "# Print of basic statistics\n",
    "print(\"Target Mean:\", target_mean)\n",
    "print(\"Target Median:\", target_median)\n",
    "print(\"Target Standard Deviation:\", target_std)\n",
    "print(\"Target Minimum:\", target_min)\n",
    "print(\"Target Maximum:\", target_max)\n",
    "\n",
    "# Plot of a histogram of the target variable\n",
    "plt.hist(df['target'])\n",
    "plt.xlabel('Target')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Target Variable')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ojia9AzuYRJ"
   },
   "source": [
    "> Describe your results here\n",
    "\n",
    "I prefer using accuracy as a baseline metric since the dataset might be balanced. If the dataset is imbalanced, we might want to use precision, recall, or F1-score instead.\n",
    "\n",
    "Accuracy: It measures the proportion of correctly classified instances over the total number of instances. This metric is useful when we have a balanced dataset and all classes are equally important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v13jy9tBuYRJ"
   },
   "source": [
    "# Question 3\n",
    "- Without using PCA, create a logistic regression model using practices discussed in class.  \n",
    "- Which model would you choose? Explain your results in the markdown cells.    \n",
    "- What is the accuracy, precision, and recall for the test data?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bQ9MfyDEuYRK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7033333333333334\n",
      "Precision: 0.7033333333333334\n",
      "Recall: 0.7033333333333334\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred,average='micro')\n",
    "recall = recall_score(y_test, y_pred,average='micro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = pipe.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "precision = precision_score(y_train, y_pred_train,average='micro')\n",
    "recall = recall_score(y_train, y_pred_train,average='micro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMpFqt5ouYRK"
   },
   "source": [
    "> Describe results here\n",
    "    \n",
    "    I prefer using Logistic regression.The performance of the logistic regression model can be evaluated using metrics such as accuracy, precision, and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rv51rYPzuYRK"
   },
   "source": [
    "# Question 4\n",
    "- Use PCA within a pipeline to create a logistic regression model using best practices from class.  \n",
    "- Which model performs the best on the training data? Explain your results in markdown cells.  \n",
    "- What is the accuracy, precision, and recall for the test data?\n",
    "- Does this perform better than the original logistic regression model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-wNlknA2uYRK"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA(n_components=2)), (&#x27;lr&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;pca&#x27;, PCA(n_components=2)), (&#x27;lr&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=2)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('pca', PCA(n_components=2)), ('lr', LogisticRegression())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert code\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('pca', PCA(n_components=2)),\n",
    "    ('lr', LogisticRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'lr__C': 0.01, 'pca__n_components': 6}\n",
      "Best score: 0.7158333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'pca__n_components': [2, 4, 6],\n",
    "    'lr__C': [0.01, 0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipeline, param_grid=param_grid, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters:\", grid.best_params_)\n",
    "print(\"Best score:\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.70\n",
      "Precision: 0.69\n",
      "Recall: 0.70\n"
     ]
    }
   ],
   "source": [
    "#accuracy calculation for test data\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "y_pred = grid.predict(X_test)\n",
    "\n",
    "# evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy calculation for training data\n",
    "y_pred_train = pipe.predict(X_train)\n",
    "\n",
    "accuracy = accuracy_score(y_train, y_pred_train)\n",
    "precision = precision_score(y_train, y_pred_train,average='micro')\n",
    "recall = recall_score(y_train, y_pred_train,average='micro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d_fiGX8_uYRK"
   },
   "source": [
    "> Describe your results here\n",
    "\n",
    "\n",
    " To determine if the pipeline model performs better than the original logistic regression model, we can compare the accuracy, precision, and recall scores of the two models on the same test data. Here, the pipeline model has little lower scores than the original logistic regression model. Though, the performance of original logistic regression model and pipeline model is almost same,the performance of original logistic regression model is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TJuT5jSQuYRL"
   },
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WT5qujmVuYRL"
   },
   "source": [
    "- Without using PCA, create a decision tree model using best practices discussed in class.  \n",
    "- Which model performs the best on the training data? Explain your results in the markdown cells.  \n",
    "- What is the accuracy, precision, and recall for the test data?  \n",
    "- Does this perform better than either of the logistic regression models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9v8vw7TwuYRL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.66\n",
      "Precision:  0.6798572683355292\n",
      "Recall:  0.66\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Instantiate the model\n",
    "dt = DecisionTreeClassifier(random_state=123)\n",
    "\n",
    "# Fit the model on the training data\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = dt.predict(X_test)\n",
    "\n",
    "# Calculate accuracy, precision, and recall\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pE_5sySuuYRN"
   },
   "source": [
    "> Describe your results here\n",
    "\n",
    "No, the decision tree model does not perform better than either of the logistic regression models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmfzYEIRuYRN"
   },
   "source": [
    "# Question 6\n",
    "- Repeat `Question 5` but use PCA.  \n",
    "- Does this perform better than the original Decision Tree or the logistic regression models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "ECgU12jnuYRN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00       591\n",
      "         1.0       1.00      1.00      1.00       302\n",
      "         2.0       1.00      1.00      1.00       307\n",
      "\n",
      "    accuracy                           1.00      1200\n",
      "   macro avg       1.00      1.00      1.00      1200\n",
      "weighted avg       1.00      1.00      1.00      1200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a pipeline with PCA and a decision tree classifier\n",
    "pipe = Pipeline([\n",
    "    ('pca', PCA(n_components=5)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=123))\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Generate classification report for the training data\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_train = pipe.predict(X_train)\n",
    "print(classification_report(y_train, y_pred_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.73      0.70      0.71       153\n",
      "         1.0       0.56      0.65      0.60        74\n",
      "         2.0       0.61      0.56      0.59        73\n",
      "\n",
      "    accuracy                           0.65       300\n",
      "   macro avg       0.63      0.64      0.63       300\n",
      "weighted avg       0.66      0.65      0.65       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Insert code here\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Create a pipeline with PCA and a decision tree classifier\n",
    "pipe = Pipeline([\n",
    "    ('pca', PCA(n_components=5)),\n",
    "    ('dt', DecisionTreeClassifier(random_state=123))\n",
    "])\n",
    "\n",
    "# Fit the pipeline to the training data\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Generate classification report for the training data\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = pipe.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NxY2ZyXVuYRO"
   },
   "source": [
    "> Describe results here\n",
    "\n",
    "    No, the decision tree model using PCA does not perform better than either of the logistic regression models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LElYDNU9uYRO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
